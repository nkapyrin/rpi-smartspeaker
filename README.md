# rpi-smartspeaker
Демонстрация (почти) умной колонки на rPi

В этом репозитории хранится небольшой отчёт по проекту, реализованному к встрече 5 июня 2018 для школы 152.
* Демонстрацию сопровождала [презентация](MAI_MSC_L1_EngineerIntro_demo.pdf),
* [Раздаточный материал](MAI_MSC_L1_EngineerIntro_handout.pdf), который можно раздать через QR код
* [Памятка по заданию](Памятка_по_заданию.pdf) содержит немного сведений по подключению и призвана организовать выполнение проекта.

# Результат
* возможность синтезировать речь
* возможности распознавать фразы
* подключение и создание программы-дворецкого за 5 минут

# Оборудование

* Raspberry Pi 3 B
* Наушники или колонки
* Веб-камера в качестве USB-микрофона (rPi не имеет аудиокарты, звук синтезируется через PWM, но микрофонный вход не работает как таковой) с возможностью записывать звук с битрейтом 16000 или больше
* Все rPi подключались к роутеру через Ethernet-провода
* Редактировать программу отлично получилось при помощи SSH терминалов на телефонах учащихся, выполняющих работу (но подключение десятка клиентов очень плохо сказалось на производительности сети, для четырёх групп следует предусмотреть два роутера)
Попытка сделать систему с использованием Android-bluetooth микрофона или bluetooth-гарнитуры остаётся на будущее

# Предварительная настройка rPi

Чтобы подготовить новую платформу к использованию, на SD карту (16 Gb, но подойдёт всё что больше 5) был установлен образ системы Raspbian Stretch (https://www.raspberrypi.org/downloads/raspbian/)
* lsblk
* umount /dev/mmcblk0p1
* umount /dev/mmcblk0p2
* sudo dd bs=4M if=2018-04-18-raspbian-stretch.img of=/dev/mmcblk0 (длится около 7 минут)

Затем систему необходимо запустить с HDMI-монитором, клавиатурой и мышью, поскольку SSH по-умолчанию выключен. На запущенной системе, в прогармме raspi-config (вызвать из терминала), первым делом был включён SSH (Interfacing -> SSH...) и расширено доступное системе место до всего объёма SD-карточки (Advanced -> Extend partition...). SSH-подключение по умолчанию возможно с логином pi и паролем raspberry.

Затем нужно установить пакеты для распознавания и синтеза речи:
* sudo apt-get install festival festvox_ru pocketsphinx pocketsphinx-en-us

Система настроена на синтез русского языка и на распознавание английского, но использование русского словаря очень замедляет программу pocketsphinx (с 10 секунд для 1-2-секундного распознавания до 1-2 минут), поэтому пока не будет найдет или сделан оптимизированный словарь, будем мириться с лингвистическими ограничениями.

Затем в папке пользователя системы каждого rPi был развёрнут пакет из папки rPi_package:
* скрипт setup.sh, запуск которого создаёт папку ползователя и копирует туда шаблонную программы,(говорящую "Привет!")
* код code.py, в котором собраны врапперы для вызова процессов записи с микрофона, воспроизведения, распознавания, и синтеза речи
* простейшая программа test.py
* не забыть chmod +x setup.sh

# Проверка оборудования

Чтобы убедиться, что микрофон работает, можно записать и воспроизвести звуковой файл:

* arecord -D hw:1,0 -d 2 -f cd -c 1 -r 16000 test.wav
* aplay test.wav

Список устройств, воспринятых звуковым менеджером ALSA:

* arecord -l
* aplay -l

Микшер, чтобы изменять урвоень звука:

* amixer

# Код программы-дворецкого

```python
#encoding:itf-8
from code import *
say( "Здрдавствуйте, как вас представить?" )
n = listen(2) # имеет тип <unicodoe>
say( "Добро пожаловать" ); say(n)
# Сложить unicode и строку бывает затруднительно
```

можно упаковать программу в цикл

```python
#encoding:itf-8
from code import *
n = ""
while len( n ) < 3:
    say( "Здрдавствуйте, как вас представить?" )
    n = listen(2) # имеет тип <unicodoe>
    if len(n) < 3: continue
    say( "Добро пожаловать" ); say(n)
```

другой вариант, в котором распознавание происходит не с микрофона, а из заранее записанного файла (при дефиците микрофонов)

```python
#encoding:itf-8
from code import *
# Записать файл можно из коммандной строки, или вписав сюда строку rec(2, "test.wav")
say( "Здрдавствуйте, как вас представить?" )
n = stt( "test.wav" )
say( "Добро пожаловать" ); say(n)
```

Последняя строка может иметь вид (не протестировано):

```python
say( "Добро пожаловать" + say(n).decode("utf-8") ) # а, может быть, encode...
```

# Выполнение работы

После беглого размышления на тему *варианта алгоритма*, который должен реализовывать диалоговый агент, приступить к выполнению можно:
* запуск ./setup.sh alex создаёт рабочее место для пользователя alex
* (потом нужно перейти в папку alex --> cd alex)
* запуск nano test.py позволяет модифицировать программу
* запуск python.py

Любой SSH клиент для Android (например, ConnectBot) и iOS (например, Cathode) позволяет работать с rPi при условии, что все находятся в единой локальной сети, и учащиеся знают IP своего rPi.

# Источники мудрости
* https://elinux.org/RPi_Text_to_Speech_(Speech_Synthesis)
* http://raspberrypi.ru/blog/153.html
* https://cmusphinx.github.io/wiki/raspberrypi/
* https://howchoo.com/g/ztbhyzfknze/how-to-install-pocketsphinx-on-a-raspberry-pi#download-the-latest-version-of-sphinxbase-and-pocketsphinx
* https://sourceforge.net/projects/cmusphinx/files/Acoustic%20and%20Language%20Models/
* http://youness.net/raspberry-pi/bluetooth-headset-raspberry-pi
* http://home-smart-home.ru/raspberry-pi-pocketsphinx-offlajn-raspoznavanie-rechi-i-upravlenie-golosom/
