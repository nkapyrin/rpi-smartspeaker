# rpi-smartspeaker
Демонстрация (почти) умной колонки на rPi

В этом репозитории хранится небольшой отчёт по проекту, реализованному к встрече 5 июня 2018 для школы 152.
* Демонстрацию сопровождала [презентация](MAI_MSC_L1_EngineerIntro_demo.pdf),
* [Раздаточный материал]([презентация](MAI_MSC_L1_EngineerIntro_handout.pdf), который можно раздать через QR код
* [Памятка по заданию](Памятка по заданию.pdf) содержит немного сведений по подключению и призвана организовать выполнение проекта.

# Результат

* возможность синтезировать речь
* возможности распознавать фразы
* подключение и создание программы-дворецкого за 5 минут

# Оборудование

* Raspberry Pi 3 B (никаких специфических требований к платформе, правда, кроме удобной ОС и менеджера пакетов)
* Наушники или колонки
* Веб-камера в качестве USB-микрофона (rPi не имеет аудиокарты, звук синтезируется через PWM, но микрофонный вход не работает как таковой)
* Все rPi подключались к роутеру через Ethernet-провода
* Редактировать программу отлично получилось при помощи SSH терминалов на телефонах учащихся, выполняющих работу (но подключение десятка клиентов очень плохо сказалось на производительности сети, для четырёх групп следует предусмотреть два роутера)
Попытка сделать систему с использованием Android-bluetooth микрофона или bluetooth-гарнитуры остаётся на будущее

# Предварительная настройка rPi

Чтобы подготовить новую платформу к использованию, на SD карту (16 Gb, но подойдёт всё что больше 5) был установлен образ системы Raspbian Stretch (https://www.raspberrypi.org/downloads/raspbian/)
* $ lsblk
* $ umount /dev/mmcblk0p1
* $ umount /dev/mmcblk0p2
* $ sudo dd bs=4M if=2018-04-18-raspbian-stretch.img of=/dev/mmcblk0

Установка длится около 7 минут. Затем систему необходимо запустить с HDMI-монитором, клавиатурой и мышью, поскольку SSH по-умолчанию выключен. На запущенной системе, в прогармме raspi-config (вызвать из терминала), первым делом был включён SSH (Interfacing -> SSH...) и расширено доступное системе место до всего объёма SD-карточки (Advanced -> Extend partition...). Затем нужно установить пакеты для распознавания и синтеза речи:
* $ sudo apt-get install festival festvox_ru pocketsphinx pocketsphinx-en-us

При такой установке, система настроена на синтез русского языка и на распознавание английского, но использование русского словаря очень замедляет программу pocketsphinx (с 10 секунд для 1-2-секундного распознавания до 1-2 минут), поэтому пока не будет найдет или сделан оптимизированный словарь, будем мириться с лингвистическими ограничениями.

Затем на каждом rPi был развёрнут пакет, составляющий основную часть данного репозитория:
* скрипт setup.sh, запуск которого создаёт папку ползователя и копирует туда шаблонную программы,(говорящую "Привет!")
* код code.py, в котором собраны врапперы для вызова процессов записи с микрофона, воспроизведения, распознавания, и синтеза речи
* простейшая программа test.py
* не забыть chmod +x setup.sh

# Выполнение работы

После беглого размышления на тему *варианта алгоритма*, который должен реализовывать диалоговый агент, приступить к выполнению можно:
* запуск ./setup.sh alex создаёт рабочее место для пользователя alex
* (потом нужно перейти в папку alex --> cd alex)
* запуск nano test.py позволяет модифицировать программу
* запуск python.py

Любой SSH клиент для Android (например, ConnectBot) и iOS (например, Cathode) позволяет работать с rPi при условии, что все находятся в единой локальной сети, и учащиеся знают IP своего RPi.

# Источники мудрости
* https://elinux.org/RPi_Text_to_Speech_(Speech_Synthesis)
* http://raspberrypi.ru/blog/153.html
* https://cmusphinx.github.io/wiki/raspberrypi/
* https://howchoo.com/g/ztbhyzfknze/how-to-install-pocketsphinx-on-a-raspberry-pi#download-the-latest-version-of-sphinxbase-and-pocketsphinx
* https://sourceforge.net/projects/cmusphinx/files/Acoustic%20and%20Language%20Models/
* http://youness.net/raspberry-pi/bluetooth-headset-raspberry-pi
* http://home-smart-home.ru/raspberry-pi-pocketsphinx-offlajn-raspoznavanie-rechi-i-upravlenie-golosom/
